---
title: "Naive Bayes"
author: "Nik Bear Brown"
output:
  html_document: default
  word_document: default
---

In this lesson we'll learn the how to implement Naive Bayes in R.

# Additional packages needed
 
To run the code you may need additional packages.

* If necessary install the followings packages.

`install.packages("tm");`    
`install.packages("wordcloud");`    
`install.packages("e1071");`   
`install.packages("gmodels");`  

```{r}
library(tm)
library(wordcloud)
library(e1071)
library(gmodels)
```

# Data

We will be using the SMS Spam Collection v.1, which is a public set of SMS labeled messages that have been collected for mobile phone spam research. It has one collection composed by 5,574 English, real and non-enconded messages, tagged according being legitimate (ham) or spam.   

- from http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/  

```{r}
data_url <- 'http://nikbearbrown.com/YouTube/MachineLearning/M10/sms_spam.csv'
# SMS
sms_data <- read.csv(url(data_url), stringsAsFactors = FALSE)
str(sms_data)
# convert spam/ham to factor.
sms_data$type <- factor(sms_data$type)
str(sms_data$type)
table(sms_data$type)
```

# Naive Bayes   

[Naive Bayes classifiers](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) are a family of simple probabilistic classifiers based on applying Bayes' theorem with strong (naive) independence assumptions between the features. This means that under the above independence assumptions, the conditional distribution over the class variable C is:

$$
p(C_k \vert x_1, \dots, x_n) = \frac{1}{Z} p(C_k) \prod_{i=1}^n p(x_i \vert C_k)
$$

where the evidence $Z = p(\mathbf{x})$ is a scaling factor dependent only on $x_1, \dots, x_n$, that is, a constant if the values of the feature variables are known.   

# Naive Bayes in R

```{r}
#  build a corpus using the text mining (tm) package 
sms_corpus <- Corpus(VectorSource(sms_data$text))
print(sms_corpus)
inspect(sms_corpus[1:3])
# clean up the corpus using tm_map()
CleanCorpus <- tm_map(sms_corpus, content_transformer(tolower))
CleanCorpus <- tm_map(CleanCorpus, removeNumbers )
CleanCorpus <- tm_map(CleanCorpus, removeWords, stopwords() )
CleanCorpus <- tm_map(CleanCorpus, removePunctuation )
CleanCorpus <- tm_map(CleanCorpus, stripWhitespace )
inspect(sms_corpus[1:3])
inspect(CleanCorpus[1:3])
# document-term sparse matrix
sms_dtm <- DocumentTermMatrix(CleanCorpus)
sms_dtm
#  training and test datasets
sms_data_train <- sms_data[1:4169, ]
sms_data_test  <- sms_data[4170:5559, ]
sms_dtm_train <- sms_dtm[1:4169, ]
sms_dtm_test  <- sms_dtm[4170:5559, ]
sms_corpus_train <- CleanCorpus[1:4169]
sms_corpus_test  <- CleanCorpus[4170:5559]
# check that the proportion 
prop.table(table(sms_data_train$type))
prop.table(table(sms_data_test$type))
#  word cloud visualization
wordcloud(sms_corpus_train, min.freq = 33, random.order = FALSE)
# subset the training data into spam and ham groups
spam <- subset(sms_data_train, type == "spam")
ham  <- subset(sms_data_train, type == "ham")
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
# indicator features for frequent words
findFreqTerms(sms_dtm_train, 5)
sms_dict <- findFreqTerms(sms_dtm_train, 5)
sms_train <- DocumentTermMatrix(sms_corpus_train, list(dictionary = sms_dict))
sms_test  <- DocumentTermMatrix(sms_corpus_test, list(dictionary = sms_dict))
# convert counts to a factor
convert_counts <- function(x) {
  x <- ifelse(x > 0, 1, 0)
  x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
}
# apply() convert_counts() to columns of train/test data
sms_train <- apply(sms_train, MARGIN = 2, convert_counts)
sms_test  <- apply(sms_test, MARGIN = 2, convert_counts)
#----------------------------------------------------Training a model on the data --------------------
sms_classifier <- naiveBayes(sms_train, sms_data_train$type)
sms_classifier
#----------------------------------------------     Evaluating model performance --------------------
sms_test_pred <- predict(sms_classifier, sms_test)
CrossTable(sms_test_pred, sms_data_test$type,
           prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
           dnn = c('predicted', 'actual'))
#---------------------------------------------------Improving model performance ----------------------

sms_classifier2 <- naiveBayes(sms_train, sms_data_train$type, laplace = 1)
sms_test_pred2 <- predict(sms_classifier2, sms_test)
CrossTable(sms_test_pred2, sms_data_test$type,
           prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
           dnn = c('predicted', 'actual'))
```


# Resources   

* [Data Mining Algorithms In R/Classification/Na?ve Bayes](https://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Classification/Na%C3%AFve_Bayes)    

* [Naive Bayes Classifier in r - YouTube](https://www.youtube.com/watch?v=-SeyrC4yZF4)    

* [naive Bayes in R - Josh Walters](http://joshwalters.com/2012/11/27/naive-bayes-classification-in-r.html)    

* [R: Naive Bayes Classifier](http://ugrad.stat.ubc.ca/R/library/e1071/html/naiveBayes.html)    

* [R code: classification with Naive Bayes - Katrin Erk](http://www.katrinerk.com/courses/r-worksheets/r-code-classification-with-naive-bayes)    

```












```